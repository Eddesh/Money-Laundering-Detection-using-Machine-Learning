# Semifinal_Data_Science_Club_Olympiad_Case

## Project Overview
The Gwenchana project is dedicated to identifying potential money laundering activities using synthesized financial transaction data. By employing various data analysis techniques and machine learning models, the project aims to help authorities distinguish between legitimate transactions and those that may be involved in criminal activities. The dataset models the complete money laundering cycle, including placement, layering, and integration, allowing for a comprehensive analysis of these illicit financial patterns.

### Dataset Description
The dataset, generated by IBM, comprises interactions between individuals, businesses, and banks. It includes transaction details such as the amounts paid and received, currencies, and payment formats. A small portion of the dataset represents criminal activities, with the intention of concealing illegal funds through a sequence of financial transactions. This project involves careful data preprocessing, including undersampling to balance the classes for improved model performance.

### Step 1: Data Preprocessing and Splitting
Class Imbalance: The dataset is heavily imbalanced, with legitimate transactions significantly outnumbering suspicious ones. This issue is addressed through undersampling to create a balanced dataset for training.
Data Cleaning: The dataset was cleaned by removing null values and filtering out anomalous timestamps (e.g., out-of-range years or months).
Feature Engineering: Several transformations were applied, including extracting date components from timestamps and frequency encoding for high-cardinality features.

### Step 2: Exploratory Data Analysis (EDA)
EDA was conducted to gain insights into the data's characteristics, including outlier detection in financial transaction amounts, and distribution analysis for categorical variables like payment formats and currencies. Visualization tools, such as histograms and scatter plots, provided a deeper understanding of transaction patterns that could indicate money laundering.

### Step 3: Model Training and Evaluation
The data was split into training and testing sets, and various classification models were trained to detect money laundering activities. Robust scaling was applied to normalize transaction amounts, mitigating the influence of outliers. Models were evaluated using accuracy, precision, recall, and F1 scores, with an emphasis on minimizing false negatives due to the project's security implications.

## Testing
The models used in this project include:
1. Logistic Regression: Provides a baseline for comparison, yielding moderate accuracy.
2. Random Forest: Captures complex relationships with improved accuracy and generalization.
3. XGBoost: Achieved the best results, with enhanced sensitivity to identify money laundering transactions effectively.

## Authors
Davin Edbert Santoso, Brandon Ritchie Yang, Steve Marcello Liem
